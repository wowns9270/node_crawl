크롤링 -> crawl - 기어가다 웹을 이리저리 돌아다니다 

노드로 크롤링의 장점 웹의 html 문서를 조작하는 언어가 자바스크립트 
   같은 언어라 호환성이 좋고 생산성이 좋다.

===================

csv (comma saperated value) -> 콤마(,) 와 줄바꿈으로 구분된 값

파싱 -> 자바스크립트가 아닌 데이터를 자바스크립트로 해석한다. 

노드는 조립과 같다. 

csv 파서를 구현하지 않고 || npm i csv-parse || 를 이용한다.

xlsx           || npm i xlsx ||

크롤링  || npm i axios cheerio ||

axios -> ajax 라이브러리 //   페이지를 요청하고 페이지에 대한 html이 응답된다.

cheerio -> html을 자바스크립트로 바꿔준다.

비동기 처리에서 forEach 와 for of 문의 차이

forEach -> 요청이 한번에 들어가 응답이 무작위

for of -> 요청이 순차적으로 응답도 순차

===========================================

다시 엑셀에 쓰는 방법은 다른 모듈 add_to_sheet.js을 만들어 

진행했는데 이러한 방법만 아는 것으로 넘어감


puppeteer//   npm i puppeteer 

2-2

영화목록 csv로 url을 받아서 puppeteer 로  브라우저를 조작해

평점을 찾고 콘솔 표시

=============================================
day5

csv에 파싱된 정보를 다시 쓰는법 || npm i csv-stringify || 설치

사람이 하는 것 처럼 보이기 위해 setUserAgent 를 통해 바꾸고 시간간격 (page.waitfor(1---))을 통해 조정

axios 는 http 통신 라이브러리 

url.replace(/\?.*$/,'') 정규표현식? 쿼리스트링을 간편하게 날릴 수 있다.

브라우저 사이즈는 launch() -> args 속성 '--window-size=1920,1080' 으로 조절 가능하고

페이지 사이즈는 page.viewport( weight : 1920, height : 1080 ) 으로 조절

img 는 aixos로 버퍼를 받고 형식 arraybuffer로 받고 fs.writeSync로 (이미지 받을경로 , 버퍼.data) 를 통해 받는다.

스크린샷은 간단하다  page.screenshot({path :경로}) 으로 찍는데 img와 다르게 버퍼를 따로 받지 않고 저장할 수 있다.

화면이나 페이지 크기에 따라 전체 페이지를 스크린샷을 하려면 옵션으로
전체는 fullPage : true 
부분은 clip : { x : □ ,y : □ ,width : □ ,height : □ }

** 선택자 **
f12 콘솔에서 $() -> document.querySelector() 를 의미한다.dj

찾을 수 있는건 tag ('div') , id ('#container) , class ('.score')

띄어쓰기 하나는 자손관계 
 
> 는 부모자식 관계
동시를 말하는거면 붙여서 쓰면된다.

============================================================================================================

day 6

infinity crwal unsplash ex1

day 7

unsplash에서 사진 30장 스크롤


